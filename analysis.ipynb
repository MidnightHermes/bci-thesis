{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f467e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from scipy.signal import welch, butter, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e2901",
   "metadata": {},
   "source": [
    "# Serialize and Unserialize RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1e34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"Sample Index\",\n",
    "    \"EEG Channel 0\", \"EEG Channel 1\", \"EEG Channel 2\", \"EEG Channel 3\",\n",
    "    \"EEG Channel 4\", \"EEG Channel 5\", \"EEG Channel 6\", \"EEG Channel 7\",\n",
    "    \"Accelerometer X\", \"Accelerometer Y\", \"Accelerometer Z\",\n",
    "    \"Timestamp\", \"Timestamp (Formatted)\"\n",
    "]\n",
    "\n",
    "# Walk through Data files, create dataframes, and pickle them\n",
    "for root, dirs, files in os.walk('./Data'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            csv_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(csv_path, './Data')\n",
    "            pkl_path = os.path.join('./Data', relative_path).replace(\".csv\", \".pickle\")\n",
    "\n",
    "            os.makedirs(os.path.dirname(pkl_path), exist_ok=True)\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(csv_path, sep='\\t', header=None)\n",
    "                # Just grab the first twelve and second to last columns\n",
    "                df_filtered = df[list(df.columns[:12]) + [df.columns[-2]]].copy()\n",
    "                # Create a new column with formatted timestamps\n",
    "                df_filtered[\"Timestamp (Formatted)\"] = pd.to_datetime(df_filtered.iloc[:, -1], unit='s', utc=True)\n",
    "                # And update the column names\n",
    "                df_filtered.columns = column_names\n",
    "                # And cut off the first row\n",
    "                df_filtered = df_filtered[1:].copy()\n",
    "                # Finally, pickle the dataframe\n",
    "                df_filtered.to_pickle(pkl_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {csv_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec917cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From pickles, create one large 'data' dataframe\n",
    "# Structure: data[participant][category][Optional[task]][Optional[subtask]]\n",
    "#   ex. data[1][Baselines]\n",
    "#   ex. data[1][Rhythm][Karate]\n",
    "#   ex. data[1][Reading][English][In]\n",
    "data = {}\n",
    "\n",
    "for root, _, files in os.walk('./Data'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pickle\") and root != './Data':\n",
    "            filepath = os.path.join(root, file)\n",
    "            parts = filepath.split(os.sep)\n",
    "            df = pd.read_pickle(filepath)\n",
    "\n",
    "            participant = parts[-2]\n",
    "            category = parts[2]\n",
    "            if category != 'Baselines':\n",
    "                task = parts[3]\n",
    "                if len(parts) > 6:\n",
    "                    data.setdefault(participant, {}).setdefault(category, {}).setdefault(task, {})[parts[4]] = df\n",
    "                else:\n",
    "                    data.setdefault(participant, {}).setdefault(category, {})[task] = df\n",
    "            else:\n",
    "                data.setdefault(participant, {})[category] = df\n",
    "\n",
    "with open('./Data/all_data_RAW.pickle', 'wb') as fp:\n",
    "    pickle.dump(data, fp)\n",
    "\n",
    "# Scale data up\n",
    "# scale_factor = 4.5 / 24 / (2**23 - 1) * 1e6\n",
    "\n",
    "# for participant in data:\n",
    "#     for category in data[participant]:\n",
    "#         category_data = data[participant][category]\n",
    "\n",
    "#         if isinstance(category_data, dict):\n",
    "#             for task in category_data:\n",
    "#                 task_data = category_data[task]\n",
    "\n",
    "#                 if isinstance(task_data, dict):\n",
    "#                     for subtask in task_data:\n",
    "#                         df = task_data[subtask]\n",
    "#                         for ch in range(8):\n",
    "#                             col = f\"EEG Channel {ch}\"\n",
    "#                             df[col] = df[col] * scale_factor\n",
    "#                 else:\n",
    "#                     df = task_data\n",
    "#                     for ch in range(8):\n",
    "#                         col = f\"EEG Channel {ch}\"\n",
    "#                         df[col] = df[col] * scale_factor\n",
    "#         else:\n",
    "#             df = category_data\n",
    "#             for ch in range(8):\n",
    "#                 col = f\"EEG Channel {ch}\"\n",
    "#                 df[col] = df[col] * scale_factor\n",
    "\n",
    "# with open('./Data/all_data_SCALED.pickle', 'ab') as fp:\n",
    "#     pickle.dump(data, fp)\n",
    "# with open('./Data/all_data_RAW.pickle', 'rb') as fp:\n",
    "#     raw_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7fe51b",
   "metadata": {},
   "source": [
    "# Serialize and Unserialize FILTERED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b803f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, title, path):\n",
    "    fig, axs = plt.subplots(8, 1, figsize=(12, 10), sharex=True)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    colors = ['#afb6be', '#7c4b8d', '#36579e', '#317159', '#ddb20d', '#fd5e34', '#e0382d', '#a25231']\n",
    "    for i, channel in enumerate([f\"EEG Channel {i}\" for i in range(8)]):\n",
    "        axs[i].plot(data[channel], linewidth=1, color=colors[i])\n",
    "        axs[i].set_ylabel(f\"Channel {i}\")\n",
    "        axs[i].set_yticklabels([])\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_xticks([])\n",
    "\n",
    "    plt.tight_layout(pad=0.5, h_pad=0)\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "b, a = butter(2, (0.1, 80.1), 'bandpass', fs=250)\n",
    "def filter_df(df):\n",
    "    for ch in [f\"EEG Channel {i}\" for i in range(8)]:\n",
    "        df[ch] = filtfilt(b, a, df[ch])\n",
    "    return df\n",
    "\n",
    "\n",
    "data_filtered = {}\n",
    "for participant in data:\n",
    "    data_filtered[participant] = {}\n",
    "    for task in data[participant]:\n",
    "        if task == 'Baselines':\n",
    "            df = data[participant][task]\n",
    "            df_filtered = filter_df(df.copy())\n",
    "            data_filtered[participant][task] = df_filtered\n",
    "            plot_data(df_filtered, f'Participant no. {participant}: {task}', f'./Data/{task}/{participant}/{participant}_filtered.png')\n",
    "        else:\n",
    "            data_filtered[participant][task] = {}\n",
    "            for subtask in data[participant][task]:\n",
    "                if task == 'Reading':\n",
    "                    data_filtered[participant][task][subtask] = {}\n",
    "                    for direction in data[participant][task][subtask]:\n",
    "                        df = data[participant][task][subtask][direction]\n",
    "                        df_filtered = filter_df(df.copy())\n",
    "                        data_filtered[participant][task][subtask][direction] = df_filtered\n",
    "                        plot_data(df_filtered, f'Participant no. {participant}: {task}, {subtask} ({direction})', f'./Data/{task}/{subtask}/{direction}/{participant}/{participant}_filtered.png')\n",
    "                else:\n",
    "                    df = data[participant][task][subtask]\n",
    "                    df_filtered = filter_df(df.copy())\n",
    "                    data_filtered[participant][task][subtask] = df_filtered\n",
    "                    plot_data(df_filtered, f'Participant no. {participant}: {task}, {subtask}', f'./Data/{task}/{subtask}/{participant}/{participant}_filtered.png')\n",
    "\n",
    "with open('./Data/all_data_FILTERED.pickle', 'wb') as fp:\n",
    "    pickle.dump(data_filtered, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c140195",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/all_data_FILTERED.pickle', 'rb') as fp:\n",
    "    data_filtered = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f97dcd",
   "metadata": {},
   "source": [
    "# Serialize and Unserialize PSD bandpower data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0104271",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\n",
    "    (0, 4, \"Delta\", \"#e0382d\"),\n",
    "    (4, 8, \"Theta\", \"#ddb20d\"),\n",
    "    (8, 10, \"Alpha\", \"#317159\"),\n",
    "    (10, 13, \"Mu\", \"#358a9e\"),\n",
    "    (13, 20, \"Beta I\", \"#36579e\"),\n",
    "    (20, 50, \"Beta II\", \"#48359e\"),\n",
    "    (50, 125, \"Gamma\", \"#7c4b8d\"),\n",
    "]\n",
    "def plot_welch_PSD(df, title, path):\n",
    "    \"\"\" Welch Power Spectral Density \"\"\"\n",
    "    channels = [f\"EEG Channel {i}\" for i in range(8)]\n",
    "    bandpowers = {ch: {} for ch in channels}\n",
    "    fig, axs = plt.subplots(4, 2, figsize=(14, 10), sharex=True, sharey=True)\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, channel in enumerate(channels):\n",
    "        freqs, power = welch(df[channel], fs=250, nperseg=1024)\n",
    "\n",
    "        axs[i].semilogy(freqs, power, color='white')\n",
    "        axs[i].set_title(f\"{channel} PSD\")\n",
    "        axs[i].set_xlim([0, 80])\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticklabels([])\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].grid(True)\n",
    "        \n",
    "        for j, (low, high, label, color) in enumerate(bands):\n",
    "            if high > 125:\n",
    "                continue\n",
    "            axs[i].axvspan(low, high, color=color, alpha=0.75, label=label)\n",
    "\n",
    "            band_mask = (freqs >= low) & (freqs <= high)\n",
    "            if np.any(band_mask):\n",
    "                band_freqs = freqs[band_mask]\n",
    "                band_power = power[band_mask]\n",
    "                peak_idx = np.argmax(band_power)\n",
    "                peak_freq = band_freqs[peak_idx]\n",
    "                peak_pow = band_power[peak_idx]\n",
    "\n",
    "                bandpowers[channel][label] = np.trapezoid(power[band_mask], freqs[band_mask])\n",
    "\n",
    "                xoffset = 5 if j == 6 or j == 0 else 0\n",
    "                yoffset = 10 if j == 0 else 0.001 if j % 2 == 1 or j == 6 else 30\n",
    "\n",
    "                axs[i].annotate(f\"{peak_freq:.1f} Hz\",\n",
    "                                xy=(peak_freq, peak_pow),\n",
    "                                xytext=(peak_freq + xoffset, peak_pow * yoffset),\n",
    "                                arrowprops=dict(arrowstyle=\"->\", lw=0.8),\n",
    "                                fontsize=8, ha='center')\n",
    "\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, ncol=7, fontsize='small', bbox_to_anchor=(0.7225, 0.9575))\n",
    "    plt.suptitle(f\"Welch Power Spectral Density - {title}\", fontsize=16)\n",
    "    fig.text(0.5, 0.01, 'Frequency (Hz)', ha='center', fontsize=12)\n",
    "    fig.text(0.01, 0.5, 'Power (μV²/Hz)', va='center', rotation='vertical', fontsize=12)\n",
    "    plt.tight_layout(pad=0.5, w_pad=1)\n",
    "    plt.subplots_adjust(top=0.89, left=0.03, bottom=0.035)\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "    return bandpowers\n",
    "\n",
    "data_bandpowers = {}\n",
    "for participant in data_filtered:\n",
    "    data_bandpowers[participant] = {}\n",
    "    for task in data_filtered[participant]:\n",
    "        if task == 'Baselines':\n",
    "            df = data_filtered[participant][task].copy()\n",
    "            data_bandpowers[participant][task] = plot_welch_PSD(df, f'Participant no. {participant}: {task}', f'./Data/{task}/{participant}/{participant}_PSD.png')\n",
    "        else:\n",
    "            data_bandpowers[participant][task] = {}\n",
    "            for subtask in data_filtered[participant][task]:\n",
    "                if task == 'Reading':\n",
    "                    data_bandpowers[participant][task][subtask] = {}\n",
    "                    for direction in data_filtered[participant][task][subtask]:\n",
    "                        df = data_filtered[participant][task][subtask][direction].copy()\n",
    "                        data_bandpowers[participant][task][subtask][direction] = plot_welch_PSD(df, f'Participant no. {participant}: {task}, {subtask} ({direction})', f'./Data/{task}/{subtask}/{direction}/{participant}/{participant}_PSD.png')\n",
    "                else:\n",
    "                    df = data_filtered[participant][task][subtask].copy()\n",
    "                    data_bandpowers[participant][task][subtask] = plot_welch_PSD(df, f'Participant no. {participant}: {task}, {subtask}', f'./Data/{task}/{subtask}/{participant}/{participant}_PSD.png')\n",
    "\n",
    "with open('./Data/all_data_BANDPOWERS.pickle', 'wb') as fp:\n",
    "    pickle.dump(data_bandpowers, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4c1521",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/all_data_BANDPOWERS.pickle', 'rb') as fp:\n",
    "    data_bandpowers = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adbbfca",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18fdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
